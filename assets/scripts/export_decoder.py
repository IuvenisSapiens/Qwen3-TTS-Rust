"""
85-Export-Stateful-ONNX.py
Qwen3-TTS Stateful Codec Decoder ONNX å¯¼å‡ºè„šæœ¬ã€‚

æ ¸å¿ƒç»éªŒå‚è€ƒï¼šExperience/01-Qwen3-Code-Predictor-Export.md
- å¼ºåˆ¶ dynamo=False ä½¿ç”¨ç»å…¸ JIT è·¯å¾„
- æ˜¾å¼å‚æ•°ç­¾åé¿å… TreeSpec æ ¡éªŒå¤±è´¥
- Dummy Input ç»´åº¦å¿…é¡»ä¸æ¨¡å‹æƒé‡å¯¹é½
"""
import os
import torch
import numpy as np
from qwen3_tts_gguf.codec_export import StatefulCodecONNXWrapper
from qwen3_tts_gguf.tokenizer_12hz.modeling_tokenizer import Qwen3TTSTokenizerV2Model

from export_config import MODEL_DIR, EXPORT_DIR

def main():
    # 1. é…ç½®
    ONNX_FILENAME = "qwen3_tts_decoder_stateful.onnx"
    os.makedirs(EXPORT_DIR, exist_ok=True)
    
    device = "cpu"
    
    # 2. åŠ è½½æ¨¡å‹
    print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    tokenizer_load_path = os.path.join(MODEL_DIR, "speech_tokenizer") if os.path.exists(os.path.join(MODEL_DIR, "speech_tokenizer")) else MODEL_DIR
    model = Qwen3TTSTokenizerV2Model.from_pretrained(tokenizer_load_path).to(device)
    wrapper = StatefulCodecONNXWrapper(model).to(device)
    wrapper.eval()
    
    # 3. è·å–å…³é”®é…ç½®
    num_layers = wrapper.num_layers
    # å…³é”®ï¼šhead_dim å¿…é¡»ä»é…ç½®ä¸­ç›´æ¥è¯»å–ï¼Œè€Œéå…¬å¼æ¨å¯¼ï¼
    # æ¨¡å‹é…ç½®ä¸­ hidden_size=512, num_heads=16, ä½† head_dim=64 (ç¡¬ç¼–ç )
    cfg = wrapper.decoder.config
    num_heads = cfg.num_key_value_heads if hasattr(cfg, 'num_key_value_heads') else cfg.num_attention_heads
    head_dim = cfg.head_dim  # ç›´æ¥è¯»å–ï¼Œé¿å…ç»´åº¦é™·é˜±
    
    print(f"   num_layers={num_layers}, num_heads={num_heads}, head_dim={head_dim}")

    
    # 4. åˆ›å»º Dummy Inputs (æ˜¾å¼ç­¾å)
    B = 1
    N = 3  # æ¯è·³ 3 å¸§
    Q = 16  # é‡åŒ–å™¨æ•°é‡
    
    dummy_audio_codes = torch.zeros(B, N, Q, dtype=torch.long, device=device)
    dummy_is_last = torch.tensor([0.0], device=device)
    dummy_pre_conv_h = torch.zeros(B, 512, 0, device=device) 
    dummy_latent_buf = torch.zeros(B, 1024, 0, device=device)
    dummy_conv_h = torch.zeros(B, 1024, 0, device=device)
    
    # KV Cache: num_layers ä¸ª K + num_layers ä¸ª V
    # Shape: [B, num_heads, past_seq, head_dim]
    dummy_kv = []
    for _ in range(num_layers):
        dummy_kv.append(torch.zeros(B, num_heads, 0, head_dim, device=device))  # K
    for _ in range(num_layers):
        dummy_kv.append(torch.zeros(B, num_heads, 0, head_dim, device=device))  # V

    
    # æ‰“åŒ…æˆå…ƒç»„
    dummy_inputs = (
        dummy_audio_codes,
        dummy_is_last,
        dummy_pre_conv_h,
        dummy_latent_buf,
        dummy_conv_h,
        *dummy_kv
    )
    
    # 5. å®šä¹‰è¾“å…¥è¾“å‡ºåç§° (æ˜¾å¼ç­¾å)
    input_names = [
        "audio_codes",
        "is_last",
        "pre_conv_history",
        "latent_buffer",
        "conv_history",
    ]
    for i in range(num_layers):
        input_names.append(f"past_key_{i}")
    for i in range(num_layers):
        input_names.append(f"past_value_{i}")
    
    output_names = [
        "final_wav",
        "valid_samples",
        "next_pre_conv_history",
        "next_latent_buffer",
        "next_conv_history",
    ]
    for i in range(num_layers):
        output_names.append(f"next_key_{i}")
    for i in range(num_layers):
        output_names.append(f"next_value_{i}")
    
    # 6. å®šä¹‰åŠ¨æ€ç»´åº¦ (å…³é”®)
    dynamic_axes = {
        "audio_codes": {1: "num_frames"},  # N
        "pre_conv_history": {2: "pre_conv_len"},
        "latent_buffer": {2: "latent_len"},
        "conv_history": {2: "conv_len"},
        "final_wav": {1: "wav_len"},
    }
    for i in range(num_layers):
        dynamic_axes[f"past_key_{i}"] = {2: f"past_seq_{i}"}
        dynamic_axes[f"past_value_{i}"] = {2: f"past_seq_{i}"}
        dynamic_axes[f"next_key_{i}"] = {2: f"next_seq_{i}"}
        dynamic_axes[f"next_value_{i}"] = {2: f"next_seq_{i}"}
    
    # 7. å¯¼å‡º FP32 æ¨¡å‹
    onnx_path_fp32 = os.path.join(EXPORT_DIR, ONNX_FILENAME)
    print(f"ğŸ“¦ æ­£åœ¨å¯¼å‡º FP32 ONNX åˆ°: {onnx_path_fp32}")
    print(f"   ä½¿ç”¨ç»å…¸ JIT è·¯å¾„ (dynamo=False)...")

    with torch.no_grad():
        torch.onnx.export(
            wrapper,
            dummy_inputs,
            onnx_path_fp32,
            input_names=input_names,
            output_names=output_names,
            dynamic_axes=dynamic_axes,
            opset_version=14,
            do_constant_folding=True,
            dynamo=False,  # å…³é”®ï¼šå¼ºåˆ¶ä½¿ç”¨ç»å…¸ JIT è·¯å¾„
        )

    fp32_size = os.path.getsize(onnx_path_fp32) / 1024 / 1024
    print(f"âœ… ONNX å¯¼å‡ºæˆåŠŸï¼æ–‡ä»¶å¤§å°: {fp32_size:.2f} MB")

    # 8. éªŒè¯æ¨¡å‹
    print("\nğŸ” æ­£åœ¨éªŒè¯ ONNX æ¨¡å‹...")
    import onnx
    onnx_model = onnx.load(onnx_path_fp32)
    onnx.checker.check_model(onnx_model)
    print("âœ… ONNX æ¨¡å‹æ ¡éªŒé€šè¿‡ï¼")

if __name__ == "__main__":
    main()
