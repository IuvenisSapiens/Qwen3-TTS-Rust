"""
stream.py - TTS è¯­éŸ³æµ
æ ¸å¿ƒé€»è¾‘æ‰€åœ¨ï¼Œç®¡ç†å•æ¬¡ä¼šè¯çš„ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒæµå¼å’Œéæµå¼åˆæˆã€‚
"""
import time
import numpy as np
from pathlib import Path
from typing import Optional, List, Tuple, Union
from .constants import PROTOCOL, map_speaker, map_language
from .result import TTSResult, Timing, LoopOutput
from .config import TTSConfig
from .predictors.talker import TalkerPredictor
from .predictors.predictor import Predictor

from . import llama, logger
from .prompt_builder import PromptBuilder, PromptData
from .utils.audio import preprocess_audio, save_temp_wav

class TTSStream:
    """
    ä¿å­˜ Talker, Predictor, Decoder è®°å¿†çš„è¯­éŸ³æµã€‚
    """
    def __init__(self, engine, n_ctx=4096, voice_path: Optional[str] = None):
        self.engine = engine
        self.assets = engine.assets
        self.tokenizer = engine.tokenizer
        self.n_ctx = n_ctx
        
        # 1. åˆå§‹åŒ–æµç‹¬ç«‹çš„ Context å’Œ Batch
        self._init_contexts()
        
        # 2. åˆå§‹åŒ–æ¨ç†æ ¸å¿ƒ (Talker & Predictor)
        self.talker = TalkerPredictor(engine.talker_model, self.talker_ctx, self.talker_batch, self.assets)
        self.predictor = Predictor(engine.predictor_model, self.predictor_ctx, self.predictor_batch, self.assets)
        
        # 3. éŸ³è‰²é”šç‚¹ (Voice)
        self.voice: Optional[TTSResult] = None
        if voice_path:
            self.set_voice(voice_path)
            
        self.decoder = getattr(engine, 'decoder', None)

    def _init_contexts(self):
        """åˆå§‹åŒ–æ­¤è¯­éŸ³æµä¸“å±çš„æ¨ç†ç¯å¢ƒ"""
        # engine.talker_model æ˜¯ LlamaModel å¯¹è±¡
        self.talker_ctx = llama.LlamaContext(self.engine.talker_model, n_ctx=self.n_ctx, embeddings=True)
        self.predictor_ctx = llama.LlamaContext(self.engine.predictor_model, n_ctx=512, embeddings=False)
        
        self.talker_batch = llama.LlamaBatch(self.n_ctx, embd_dim=2048)
        self.predictor_batch = llama.LlamaBatch(32, embd_dim=1024)

    # =========================================================================
    # æ ¸å¿ƒæ¨ç† API
    # =========================================================================

    def clone(self, 
              text: str, 
              language: str = "chinese",
              config: Optional[TTSConfig] = None,
              streaming: bool = False,
              chunk_size: int = 25,
              verbose: bool = True) -> Optional[TTSResult]:
        """
        [å…‹éš†æ¨¡å¼] ä½¿ç”¨å½“å‰æµä¸­å·²è®¾å®šçš„éŸ³è‰²é”šç‚¹ï¼ˆVoice Anchorï¼‰è¿›è¡Œè¯­éŸ³åˆæˆã€‚

        Args:
            text: å¾…åˆæˆçš„ç›®æ ‡æ–‡æœ¬ã€‚
            language: ç›®æ ‡è¯­è¨€ã€‚å¯é€‰:
                - 'chinese' (é»˜è®¤), 'english', 'japanese', 'korean'
                - 'german', 'spanish', 'french', 'russian', 'italian', 'portuguese'
                - 'beijing_dialect' (åŒ—äº¬è¯), 'sichuan_dialect' (å››å·è¯)
            config: æ¨ç†é…ç½®å¯¹è±¡ (TTSConfig)ï¼Œå¯æ§åˆ¶ Temperature, Top-P ç­‰é‡‡æ ·å‚æ•°ã€‚
            streaming: æ˜¯å¦å¯ç”¨æµå¼æ¨ç†ã€‚è‹¥ä¸º Trueï¼Œåˆ™è¾¹æ¨ç†è¾¹å‘æ’­æ”¾å™¨æ¨é€æ•°æ®ã€‚
            chunk_size: æµå¼æ¨ç†æ—¶ï¼Œæ¯ç§¯å‹å¤šå°‘å¸§ç‰¹å¾ç å³é€å»è§£ç æ’­æ”¾ä¸€æ¬¡ã€‚è¶Šå°å»¶è¿Ÿè¶Šä½ï¼Œä½†æ¯æ¬¡è§£ç ä¼šæœ‰8å¸§çš„é¢å¤–è®¡ç®—ã€‚
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ¨ç†è¿›åº¦å’Œæ—¶å»¶ç»Ÿè®¡ã€‚

        Returns:
            TTSResult å¯¹è±¡ï¼ŒåŒ…å«å®Œæ•´éŸ³é¢‘ã€ç‰¹å¾ç åŠæ€§èƒ½ç»Ÿè®¡ã€‚
        """
        if self.voice is None:
            print("[ERR] å°šæœªè®¾å®šéŸ³è‰²é”šç‚¹ï¼Œè¯·å…ˆè°ƒç”¨ set_voice()ã€‚")
            return None
            
        cfg = config or TTSConfig()
        self.talker.clear_memory()
        
        try:
            lang_id = map_language(language)
            pdata = PromptBuilder.build_clone_prompt(text, self.tokenizer, self.assets, self.voice, lang_id)
            
            # DEBUG: Dump tensor stats for alignment
            import numpy as np
            embd_flat = pdata.embd.flatten()
            print(f"DEBUG_PY: Prompt embeddings: {pdata.embd.shape} tokens (Flattened: {len(embd_flat)})")
            print(f"DEBUG_PY: Flattened prompt head: {embd_flat[:10]}")
            print(f"DEBUG_PY: Flattened prompt tail: {embd_flat[-10:]}")
            print(f"DEBUG_PY: Flattened prompt sum: {np.sum(embd_flat)}")
            print(f"DEBUG_PY: Tokenizer ids: {len(pdata.text_ids)} tokens")
            
            timing = Timing()
            timing.prompt_time = pdata.compile_time
            
            lout = self._run_engine_loop(pdata, timing, cfg, streaming=streaming, chunk_size=chunk_size, verbose=verbose)
            return self._post_process(text, pdata, lout)
        except Exception as e:
            print(f"[ERR] Clone æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def custom(self,
               text: str,
               speaker: str,
               language: str = "chinese",
               instruct: Optional[str] = None,
               config: Optional[TTSConfig] = None,
               streaming: bool = False,
               chunk_size: int = 25,
               verbose: bool = True) -> Optional[TTSResult]:
        """
        [ç²¾å“éŸ³è‰²æ¨¡å¼] ä½¿ç”¨å®˜æ–¹å†…ç½®çš„ç²¾å“é¢„è®¾éŸ³è‰²è¿›è¡Œåˆæˆï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æ¸²æŸ“æŒ‡ä»¤ã€‚

        Args:
            text: å¾…åˆæˆçš„ç›®æ ‡æ–‡æœ¬ã€‚
            speaker: ç²¾å“éŸ³è‰²åç§°ã€‚å¯é€‰:
                - å¥³æ€§: 'vivian', 'serena', 'ono_anna', 'sohee'
                - ç”·æ€§: 'ryan', 'aiden', 'uncle_fu'
                - æ–¹è¨€ä¸“ç”¨: 'eric' (å››å·è¯ç”·å£°), 'dylan' (åŒ—äº¬è¯ç”·å£°)
            language: ç›®æ ‡è¯­è¨€ (è§ clone æ–¹æ³•)ã€‚
            instruct: æ¸²æŸ“æŒ‡ä»¤ï¼Œå¦‚ "ç”¨æ¸©æŸ”çš„è¯­æ°”è¯´" æˆ– "å……æ»¡æ´»åŠ›çš„æ’­æŠ¥"ã€‚
            config: æ¨ç†é…ç½®å¯¹è±¡ (TTSConfig)ã€‚
            streaming: æ˜¯å¦å¯ç”¨æµå¼æ¨ç†ã€‚
            chunk_size: æµå¼æ¨ç†å—å¤§å°ã€‚
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†è¿›åº¦ã€‚

        Returns:
            TTSResult å¯¹è±¡ã€‚
        """
        cfg = config or TTSConfig()
        self.talker.clear_memory()
        
        try:
            spk_id = map_speaker(speaker)
            lang_id = map_language(language) if language.lower() != "auto" else None
            pdata = PromptBuilder.build_custom_prompt(text, self.tokenizer, self.assets, spk_id, lang_id, instruct)
            
            timing = Timing()
            timing.prompt_time = pdata.compile_time
            
            lout = self._run_engine_loop(pdata, timing, cfg, streaming=streaming, chunk_size=chunk_size, verbose=verbose)
            return self._post_process(text, pdata, lout)
        except Exception as e:
            logger.error(f"âŒ Custom æ¨ç†å¤±è´¥: {e}")
            return None

    def design(self,
               text: str,
               instruct: str,
               language: str = "chinese",
               config: Optional[TTSConfig] = None,
               streaming: bool = False,
               chunk_size: int = 25,
               verbose: bool = True) -> Optional[TTSResult]:
        """
        [éŸ³è‰²è®¾è®¡æ¨¡å¼] å®Œå…¨é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°æ¥è®¾è®¡å¹¶ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„éŸ³è‰²ã€‚

        Args:
            text: å¾…åˆæˆçš„ç›®æ ‡æ–‡æœ¬ã€‚
            instruct: éŸ³è‰²è®¾è®¡æè¿°ã€‚ä¾‹å¦‚ï¼š"ä½“ç°æ’’å¨‡ç¨šå«©çš„èè‰å¥³å£°ï¼ŒéŸ³è°ƒåé«˜ä¸”èµ·ä¼æ˜æ˜¾ã€‚"
            language: ç›®æ ‡è¯­è¨€ (è§ clone æ–¹æ³•)ã€‚
            config: æ¨ç†é…ç½®å¯¹è±¡ (TTSConfig)ã€‚
            streaming: æ˜¯å¦å¯ç”¨æµå¼æ¨ç†ã€‚
            chunk_size: æµå¼æ¨ç†å—å¤§å°ã€‚
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†è¿›åº¦ã€‚

        Returns:
            TTSResult å¯¹è±¡ã€‚
        """
        cfg = config or TTSConfig()
        self.talker.clear_memory()
        
        try:
            lang_id = map_language(language) if language.lower() != "auto" else None
            pdata = PromptBuilder.build_design_prompt(text, self.tokenizer, self.assets, instruct, lang_id)
            
            timing = Timing()
            timing.prompt_time = pdata.compile_time
            
            lout = self._run_engine_loop(pdata, timing, cfg, streaming=streaming, chunk_size=chunk_size, verbose=verbose)
            return self._post_process(text, pdata, lout)
        except Exception as e:
            logger.error(f"âŒ Design æ¨ç†å¤±è´¥: {e}")
            return None

    def tts(self, *args, **kwargs):
        return self.clone(*args, **kwargs)

    def _run_engine_loop(self, pdata: PromptData, timing: Timing, cfg: TTSConfig, 
                         streaming: bool = False, chunk_size: int = 25, verbose: bool = False) -> LoopOutput:
        all_codes = []
        turn_summed_embeds = []
        chunk_buffer = []
        
        if self.decoder:
            pass # ä¿¡ä»» Session è‡ªåŠ¨æ¸…ç†é€»è¾‘
            
        for step_codes, summed_vec in self._run_engine_loop_gen(pdata, cfg, timing):
            all_codes.append(step_codes) # ä¿æŒ numpy çŠ¶æ€ï¼Œä¾› decoder ä½¿ç”¨
            turn_summed_embeds.append(summed_vec)
            
            if streaming and self.decoder:
                chunk_buffer.append(step_codes)
                if len(chunk_buffer) >= chunk_size:
                    self.decoder.decode(np.array(chunk_buffer), is_final=False, stream=True)
                    chunk_buffer = []

        if streaming and self.decoder:
            self.decoder.decode(np.array(chunk_buffer) if chunk_buffer else np.zeros((0, 16)), is_final=True, stream=True)

        return LoopOutput(all_codes=all_codes, summed_embeds=turn_summed_embeds, timing=timing)

    def _create_sampler(self, do_sample: bool, temperature: float, top_p: float, top_k: int) -> llama.LlamaSampler:
        """åˆ›å»ºåŸç”Ÿé‡‡æ ·å™¨å®ä¾‹"""
        if do_sample:
            return llama.LlamaSampler(
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                seed=None
            )
        else:
            return llama.LlamaSampler(temperature=0)

    def _run_engine_loop_gen(self, pdata: PromptData, cfg: TTSConfig, timing: Timing):
        t_pre_s = time.time()
        m_hidden = self.talker.prefill(pdata.embd, seq_id=0)
        timing.prefill_time = time.time() - t_pre_s
        
        # 1. åˆå§‹åŒ–ä¸¤çº§åŸç”Ÿé‡‡æ ·å™¨
        talker_sampler = self._create_sampler(cfg.do_sample, cfg.temperature, cfg.top_p, cfg.top_k)
        predictor_sampler = self._create_sampler(cfg.sub_do_sample, cfg.sub_temperature, cfg.sub_top_p, cfg.sub_top_k)
            
        step_idx = 0
        try:
            for step_idx in range(cfg.max_steps):
                # DEBUG: Print m_hidden sum (from Talker)
                import numpy as np
                print(f"DEBUG_PY: Step {step_idx} m_hidden sum: {np.sum(m_hidden):.5f}")
                # Print first 5 values for detailed comparison
                print(f"DEBUG_PY: Step {step_idx} m_hidden[0..5]: {m_hidden[:5]}")
                
                # ---------------- Talker Stage ----------------
                code_0 = talker_sampler.sample(self.talker.ctx)
                print(f"DEBUG_PY: Step {step_idx} code_0: {code_0}")
                
                if code_0 == PROTOCOL["EOS"]:
                    print(f"DEBUG_PY: Step {step_idx} EOS reached at {code_0}")
                    break
                
                t_c_s = time.time()
                
                # ---------------- Predictor Stage ----------------
                # æ˜¾å¼ä¼ é€’å¤ç”¨çš„é‡‡æ ·å™¨
                step_codes, step_embeds_2048 = self.predictor.predict_frame(
                    m_hidden, 
                    code_0, 
                    sampler=predictor_sampler
                )
                
                if step_idx == 0:
                   # DEBUG_PY: Print Top 10 Logits
                   logits_ptr = self.talker.ctx.get_logits()
                   n_vocab = 152064 # Default Qwen3 vocab
                   try:
                        n_vocab = llama.llama_vocab_n_tokens(self.talker.model.vocab)
                   except:
                        pass
                   
                   # Create numpy view (copy to be safe)
                   logits = np.ctypeslib.as_array(logits_ptr, shape=(n_vocab,)).copy()
                   
                   
                   # Create numpy view (copy to be safe) - ASSUME DENSE for testing
                   # If dense, size is n_tokens * n_vocab = 111 * 3072 = 340992
                   # We need to be careful not to Segfault if sparse.
                   # Let's try to access the last token's position: 110.
                   last_idx = 110 # Hardcoded for this prompt
                   
                   try:
                       # Offset pointer
                       import ctypes
                       logit_type = ctypes.c_float
                       
                       # Index 0
                       logits_0 = np.ctypeslib.as_array(logits_ptr, shape=(n_vocab,)).copy()
                       top_k_0 = np.argsort(logits_0)[-5:][::-1]
                       print(f"DEBUG_PY: Step 0 Top 5 Logits (Index 0):")
                       for idx in top_k_0:
                           print(f"        Code {idx}: {logits_0[idx]:.5f}")

                       # Index 110
                       # Pointer arithmetic: ptr + (last_idx * n_vocab)
                       # Cast to void_p, add bytes? No, ctypes pointer arithmetic works by element size.
                       offset_ptr = ctypes.cast(
                           ctypes.addressof(logits_ptr.contents) + (last_idx * n_vocab * ctypes.sizeof(logit_type)),
                           ctypes.POINTER(logit_type)
                       )
                       logits_end = np.ctypeslib.as_array(offset_ptr, shape=(n_vocab,)).copy()
                       top_k_end = np.argsort(logits_end)[-5:][::-1]
                       print(f"DEBUG_PY: Step 0 Top 5 Logits (Index {last_idx}):")
                       for idx in top_k_end:
                           print(f"        Code {idx}: {logits_end[idx]:.5f}")
                   except Exception as e:
                       print(f"DEBUG_PY: Failed to access Index {last_idx}: {e}")

                   print(f"DEBUG_PY: Step 0 Codes[1..8]: {step_codes[:8]}")
                timing.predictor_loop_time += (time.time() - t_c_s)
                
                # DEBUG: Print step_embeds_2048 sum
                embeds_sum = np.sum(np.sum(step_embeds_2048, axis=0))
                print(f"DEBUG_PY: Step {step_idx} step_embeds_2048 total sum: {embeds_sum:.5f}")
                
                t_m_s = time.time()
                summed = np.sum(step_embeds_2048, axis=0) + self.assets.tts_pad.flatten()
                
                print(f"DEBUG_PY: Step {step_idx} feedback sum: {np.sum(summed):.5f}")
                
                m_hidden = self.talker.decode_step(summed, seq_id=0)
                timing.talker_loop_time += (time.time() - t_m_s)
                
                yield step_codes, summed
                
        finally:
            talker_sampler.free()
            predictor_sampler.free()
            
        timing.total_steps = len(pdata.embd) + step_idx

    def _post_process(self, 
                     text: str, 
                     pdata: PromptData, 
                     lout: LoopOutput) -> TTSResult:
        audio = None
        if self.decoder:
            t0 = time.time()
            audio = self.decoder.decode(np.array(lout.all_codes), is_final=True, stream=False)
            lout.timing.decoder_render_time = time.time() - t0

        return TTSResult(
            audio=audio,
            text=text,
            text_ids=pdata.text_ids,
            spk_emb=pdata.spk_emb,
            codes=np.array(lout.all_codes),
            summed_embeds=lout.summed_embeds,
            stats=lout.timing
        )

    def reset(self):
        self.talker_ctx.clear_kv_cache()
        self.predictor_ctx.clear_kv_cache()
        self.voice = None
        logger.info("æ‰« [Stream] è®°å¿†ä¸éŸ³è‰²å·²æ¸…é™¤ã€‚")

    def join(self, timeout: Optional[float] = None):
        """é˜»å¡ç›´è‡³å½“å‰æµæ‰€æœ‰éŸ³é¢‘ï¼ˆè§£ç +æ’­æŠ¥ï¼‰å…¨éƒ¨å®Œæ¯•"""
        if self.decoder:
            # 1. å…ˆç­‰è§£ç å™¨æŠŠæ´»å¹²å®Œ (Bitstream -> PCM)
            self.decoder.join_decoder(timeout)
            # 2. å†ç­‰æ’­æ”¾å™¨æŠŠå£°éŸ³æ”¾å®Œ (PCM -> å£°å¡)
            self.decoder.join_speaker(timeout)

    def shutdown(self):
        # è®© Python GC å¤„ç†å†…å­˜é‡Šæ”¾ (_del_ ä¼šè°ƒç”¨ free)
        self.talker_batch = None
        self.talker_ctx = None
        self.predictor_batch = None
        self.predictor_ctx = None

    # =========================================================================
    # éŸ³è‰²è®¾ç½® API (Voice Management)
    # =========================================================================

    def set_voice(self, source: Union[TTSResult, str, Path], text: Optional[str] = None, **kwargs) -> Union[bool, TTSResult]:
        """ç»Ÿä¸€è®¾ç½®å½“å‰æµçš„éŸ³è‰²é”šç‚¹ã€‚è¿”å›ç”Ÿæˆçš„ TTSResult æˆ– Falseã€‚"""
        try:
            success = False
            if isinstance(source, TTSResult):
                success = self._set_voice_from_result(source)
            else:
                source_p = Path(source)
                if source_p.suffix.lower() == ".json":
                    success = self._set_voice_from_json(source_p)
                elif source_p.suffix.lower() in [".wav", ".mp3", ".flac", ".m4a", ".opus"]:
                    success = self._set_voice_from_audio(source_p, text or "", **kwargs)
                else:
                    # å°è¯•ä½œä¸ºå†…ç½®è¯´è¯äººå¤„ç†
                    return self.set_voice_from_speaker(str(source), text or "ä½ å¥½", **kwargs)
            
            return self.voice if success else False
        except Exception as e:
            print(f"[ERR] è®¾ç½®éŸ³è‰²æ—¶å‡ºç°æ— æ³•é¢„æ–™çš„å¼‚å¸¸: {e}")
            return False

    def _set_voice_from_result(self, res: TTSResult) -> bool:
        if not res.is_valid_anchor:
            print("[ERR] æä¾›çš„ TTSResult ä¸æ˜¯æœ‰æ•ˆçš„éŸ³è‰²é”šç‚¹ (ç¼ºå°‘ codes æˆ– spk_emb)ã€‚")
            return False
        self.voice = res
        print(f"[Voice] éŸ³è‰²å·²åˆ‡æ¢ä¸º: {res.text[:20]}...")
        return True

    def _set_voice_from_json(self, path: Path) -> bool:
        """ä» JSON æ–‡ä»¶æ¢å¤éŸ³è‰²é”šç‚¹"""
        if not path.exists():
            logger.error(f"âŒ æœªæ‰¾åˆ°éŸ³è‰² JSON æ–‡ä»¶: {path}")
            return False
        try:
            res = TTSResult.from_json(str(path))
            return self._set_voice_from_result(res)
        except Exception as e:
            print(f"[ERR] è§£æéŸ³è‰² JSON å¤±è´¥ ({path.name}): {e}")
            return False

    def _set_voice_from_audio(self, wav_path: Path, text: str) -> bool:
        """ä»éŸ³é¢‘æ–‡ä»¶å…‹éš†éŸ³è‰²ï¼šä½¿ç”¨ pydub æ ‡å‡†åŒ–è¾“å…¥"""
        if self.engine.encoder is None:
            print("[ERR] ç¼–ç å™¨æ¨¡å—æœªåŠ è½½ï¼Œæ— æ³•æ‰§è¡ŒéŸ³è‰²å…‹éš†ã€‚")
            return False
            
        print(f"[Voice] æ­£åœ¨ä»éŸ³é¢‘æå–éŸ³è‰²ç‰¹å¾: {wav_path.name}")
        
        # 1. ä¸‡èƒ½æ ¼å¼è½¬æ¢ä¸é¢„å¤„ç†
        samples = preprocess_audio(wav_path)
        if samples is None:
            return False
            
        # 2. äº¤äº’è¿‡æ¸¡: ç¼–ç å™¨ç›®å‰åªæ¥å—æ–‡ä»¶è·¯å¾„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸´æ—¶ wav
        temp_wav = save_temp_wav(samples)
        try:
            codes, spk_emb = self.engine.encoder.encode(temp_wav)
            res = TTSResult(text=text, text_ids=self.tokenizer.encode(text).ids, spk_emb=spk_emb, codes=codes.tolist())
            return self._set_voice_from_result(res)
        except Exception as e:
            print(f"[ERR] éŸ³å£°ç‰¹å¾æå–å¤±è´¥: {e}")
            return False
        finally:
            if os.path.exists(temp_wav):
                try: os.remove(temp_wav)
                except: pass

    def set_voice_from_speaker(self, speaker_id: str, text: str, **kwargs) -> Optional[TTSResult]:
        """ä»å†…ç½®è¯´è¯äººç”ŸæˆéŸ³è‰²é”šç‚¹å¹¶è®¾ç½®"""
        try:
            logger.info(f"ğŸ“ æ­£åœ¨ä»å†…ç½®è¯´è¯äººåˆå§‹åŒ–éŸ³è‰²æ ¸å¿ƒ: {speaker_id}")
            # kwargs åŒ…å« language, streaming, verbose ç­‰
            res = self.custom(text, speaker_id, **kwargs)
            if res:
                self._set_voice_from_result(res)
                return res
            return None
        except Exception as e:
            print(f"[ERR] å†…ç½®éŸ³è‰²åˆå§‹åŒ–å¤±è´¥: {e}")
            return None
