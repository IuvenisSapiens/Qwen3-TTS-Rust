# Qwen3-TTS Rust

[ÁÆÄ‰Ωì‰∏≠Êñá](../README.md) | [English](README_EN.md) | [Deutsch](README_DE.md)

Dieses Projekt ist eine leistungsstarke Rust-Implementierung von Qwen3-TTS. Die wichtigsten Durchbr√ºche sind die **"Anweisungsgesteuerte (Instruction-Driven)"** Synthese und das **"Zero-Shot Custom Speaker Cloning"**. Durch die Kombination der Speichersicherheit von Rust mit der effizienten Inferenz von llama.cpp/ONNX bietet es eine Text-to-Speech-L√∂sung auf Industrieniveau.

## üöÄ Kernmerkmale: Anweisungen & Anpassung

Im Gegensatz zu herk√∂mmlichen TTS-Systemen erm√∂glicht Qwen3-TTS Rust die Steuerung des Sprechstils durch einfache Textanweisungen und das Klonen jeder Stimme in Sekundenschnelle.

### 1. Anweisungsgesteuerter (Instruction-Driven) TTS
Sie k√∂nnen Anweisungen zu Emotionen, Geschwindigkeit oder Stil direkt in den Text einf√ºgen. Das Sprachmodell (LLM) nutzt sein semantisches Verst√§ndnis, um zu "wissen", wie der Text gelesen werden soll.
> **Beispiel**: `cargo run --example qwen3-tts -- --text "[Fr√∂hlich] Hallo! Das Wetter heute ist einfach fantastisch!" --voice-file "speaker.json"`

### 2. Benutzerdefinierte Stimmen (Custom Speakers)
Nicht mehr auf voreingestellte Stimmen beschr√§nkt. Mit nur einem **24kHz WAV-Referenzaudio** k√∂nnen Sie ein einzigartiges Voice-Pack erstellen.
-   **One-Click-Extraktion**: Extrahiert automatisch Sprecher-Embeddings und akustische Merkmale (Codec-Codes).
-   **Dauerhafte Speicherung**: Nach der Extraktion als `.json` gespeichert, kein Original-Audio f√ºr die zuk√ºnftige Verwendung erforderlich.

## üåü Technische Vorteile

-   **Plattform√ºbergreifend/Backends**: Tiefe Anpassung f√ºr **Windows / Linux / macOS**, unterst√ºtzt **CPU / CUDA / Vulkan / Metal**.
-   **Zero-Config Runtime**: Automatische Verwaltung von `llama.cpp` (b7885) und `onnxruntime` Bin√§rdateien, mit plattform√ºbergreifendem Asset-Mapping und dynamischem Laden.
-   **Hybrid-Engine**: 
    -   **LLM-Inferenz**: Verwendet llama.cpp f√ºr die Konvertierung von Text in akustische Merkmale, standardm√§√üig mit **Vulkan** Hardwarebeschleunigung.
    -   **Audio-Dekodierung**: Verwendet ONNX Runtime (CPU) f√ºr effizientes Streaming-Dekodieren mit minimaler Latenz.

## üõ†Ô∏è Kurzanleitung

### Benutzerdefinierte Stimme erstellen und speichern
```powershell
cargo run --example qwen3-tts -- `
    --model-dir models `
    --ref-audio "path/to/me.wav" `
    --ref-text "Der Text, den ich w√§hrend der Aufnahme gesprochen habe" `
    --save-voice "models/presets/my_voice.json" `
    --text "[Aufgeregt] Hey! Meine Stimme wurde gerade in die Rust-Engine geklont!" `
    --max-steps 512
```

## üìÇ Automatisierte Verwaltung
Das Programm verf√ºgt √ºber eine integrierte Logik zum **automatischen Download von Modellen und Runtimes**. Beim ersten Start werden die Modelle von HuggingFace und die entsprechenden offiziellen `llama.cpp` Bin√§rdateien je nach Betriebssystem automatisch in das Verzeichnis `runtime/` heruntergeladen.

## üìú Lizenz & Danksagung
- **MIT / Apache 2.0** Lizenz.
- Dank an das offizielle [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) Repository f√ºr die Modelle und technische Basis.
- Dank an [Qwen3-TTS-GGUF](https://github.com/HaujetZhao/Qwen3-TTS-GGUF) f√ºr die Inspiration zum GGUF-Inferenzfluss.
